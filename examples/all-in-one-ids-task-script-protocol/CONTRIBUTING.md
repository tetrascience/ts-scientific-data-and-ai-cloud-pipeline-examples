# Developing demo-ssp <!-- omit in toc -->

## Table of Contents <!-- omit in toc -->

- [Quickstart](#quickstart)
- [Getting started](#getting-started)
- [Installation](#installation)
- [Running tests and updating auto-generated files](#running-tests-and-updating-auto-generated-files)
- [Upload artifacts to TDP](#upload-artifacts-to-tdp)
  - [About preparing requirements.txt for Python dependencies](#about-preparing-requirementstxt-for-python-dependencies)
- [Create a pipeline](#create-a-pipeline)
- [Artifact identity (namespace, type slug and version)](#artifact-identity-namespace-type-slug-and-version)

## Quickstart

The files have placeholders for `{YOUR_ORG_SLUG}` and `{YOUR_SLUG_PREFIX}` which need to be replaced.

- Replace `{YOUR_ORG_SLUG}` with your org-slug
- Replace `{YOUR_SLUG_PREFIX}` with your username and a hyphen, e.g., `jfoldager-`

See [Installation](#installation) and [Upload artifacts to TDP](#upload-artifacts-to-tdp) for getting started.

## Overview

This example folder structure contains an IDS, task script and protocol for use with self-service pipelines.
These three artifacts can be uploaded to the Tetra Data Platform (TDP) and used to create a data pipeline.

More information about self-service artifacts can be found in the documentation here: https://developers.tetrascience.com/docs/self-service-pipelines-overview

This project includes:

- A complete example of an IDS, task script and protocol all in one folder structure, which can be uploaded and used as a self-service pipeline.
- A programmatic definition of an IDS using `ts-ids-core`.
- Examples of testing with `pytest`, including mocked responses from the `context` interface from `ts-sdk`.
- Use of `poetry` for Python dependency management.

The IDS artifact is contained in the `ids` folder.
The protocol artifact is contained in the `protocol` folder.
The task script artifact is contained in the `task_script` folder.

The key folders and files are listed below:

```
.
├── CONTRIBUTING.md - Developer instructions for working in this project
├── ids - IDS artifact files
│  ├── __init__.py
│  ├── __tests__ - Tests for the IDS schema
│  ├── athena.json - Athena specification
│  ├── demo_ssp_ids - IDS package containing programmatic schema
│  │  ├── __init__.py
│  │  ├── expected.py - Example programmatic IDS data
│  │  └── schema.py - Programmatic IDS - add Python modules and sub-packages as needed for larger schemas
│  ├── elasticsearch.json - Elasticsearch specification
│  ├── expected.json - Example IDS JSON data (generated by a snapshot test)
│  ├── manifest.json - Metadata about the IDS
│  ├── README.md - Documentation viewable in TDP for this IDS
│  ├── schema.json - JSON Schema (generated from schema.py)
│  ├── pyproject.toml - Poetry project definition for IDS
│  └── poetry.lock - Locked dependencies for IDS
├── protocol - Protocol artifact files
│  ├── manifest.json - Metadata about the protocol
│  ├── protocol.yml - The protocol definition
│  └── README.md - Documentation viewable in TDP for this protocol
├── task_script - Task script artifact files
│  ├── __init__.py
│  ├── __tests__ - `pytest` tests including integration and unit tests
│  ├── config.json - The task script configuration file
│  ├── main.py - The entrypoint to the task script (as specified in `config.json`)
│  ├── manifest.json - Metadata about the task script
│  ├── README.md - Documentation viewable in TDP for this task script
│  ├── demo_ssp_task_script - Task script package containing logic
│  │  └── parse.py - Task script logic. Add more Python modules and sub-packages as needed for larger task scripts
│  ├── tools - Utility scripts for task script development
│  │  └── generate_requirements.py - Script to generate requirements.txt
│  ├── pyproject.toml - Poetry project definition for task script
│  ├── poetry.lock - Locked dependencies for task script
│  └── requirements.txt - Generated Python dependencies for TDP deployment
├── example-input - Example input files which would be uploaded to the data lake
├── example-output - Example output files generated from the input files
└── README.md - Documentation
```

For larger projects where multiple IDSs, task scripts or protocols need to be created together, it can be beneficial to create separate repositories for the IDS(s), task script(s) and protocol(s) instead of keeping them together in one package.
This package structure is intended to be an all-in-one example of a straightforward IDS, task script and protocol.

After copying this example, initialize it as a git repository to keep track of changes.

## Installation

This project is using `poetry` to manage Python dependencies.

A typical developer setup, including selecting the python interpreter with `pyenv`, is:

```sh
pyenv local 3.11

cd ids
poetry env use 3.11
poetry install
cd ..

cd task_script
poetry env use 3.11
poetry install
cd ..

```

## Running tests and updating auto-generated files

Tests are located in the `ids/__tests__` and `task_script/__tests__` directories.

To run all tests, run `poetry run pytest` in both folders.

The tests include snapshot tests, which compare the output of a test with the content of a file, and can be used to automatically update those snapshot files with the expected content.
Snapshot tests are used to update the following files:

- `ids/schema.json` is compared with the JSON schema produced by the definition in `ids/demo_ssp_ids/schema.py`
- `ids/expected.json` is compared with the output from `ids/demo_ssp_ids/expected.py`
- `ids/elasticsearch.json` is compared with the output `ts-ids-es-json-generator`, which produces a simple default Elasticsearch mapping from the schema.
  - This test can be deleted if you would prefer to create a custom Elasticsearch mapping. Note that the Elasticsearch mapping is also checked as part of `ts-ids-validator` so any mistakes leading to an invalid mapping will be caught before the IDS is uploaded to TDP.
- All files in `example-output` are generated by taking files from `example-input` as inputs to the main task script function in `task_script/main.py`, which produces IDS JSON files which are saved to `example-output`.

These snapshot files don't need to be maintained manually - after making changes in the repo, update snapshot files by running `poetry run pytest --snapshot-update`.
The modified snapshot files can be checked with `git diff` before being committed.

## Upload artifacts to TDP

Get started with self-service pipelines by following documentation here: <https://developers.tetrascience.com/docs/self-service-pipelines-overview>.
Before uploading artifacts you will need to choose a unique combination of namespace, type slug and version - see the section on artifact identity below.

After getting set up, the `ts-cli` command line script is available for uploading artifacts and can be used to upload all three artifacts.

The ids, task script and protocol depend on each other, and should be uploaded in the following order:

1. IDS
2. Task script
3. Protocol

The task script has a build step which needs to be run before uploading the task script.
The build step packages some of the dependencies into a `dependencies/` folder which is then included when uploading the task script. This step is needed when relying on private Python packages which are not available publicly on PyPI.

The arfifacts are built and uploaded using the following commands:

```sh
ts-cli publish ids --config {path to ts-sdk-cfg.json}
```

```sh
cd task_script
poetry run generate-requirements
ts-cli publish --config {path to ts-sdk-cfg.json}
cd ..
```

```sh
ts-cli publish protocol --config {path to ts-sdk-cfg.json}
```

### About preparing requirements.txt for Python dependencies

Before uploading the task script, we need to create a `requirements.txt` file which is used by the TDP build process to install Python dependencies.
This demo uses privately hosted Python packages which are not available publicly on PyPI: `ts-ids-core` and `ts-ids-components`.
The task script build process only has access to publicly hosted packages from PyPI, so to make these dependencies available we will first download them to a `dependencies/` folder using a script.

The script to generate `requirements.txt` is made available as a command-line script `generate-requirements` which can be run in the virtual environment created by `poetry` after `poetry install`.
The script runs `poetry` and `pip` as subprocesses: to inspect what the script does before running it, check `task_script/tools/generate_requirements.py`.

After the script has run without error, `task_script/requirements.txt` and `task_script/dependencies/` should be populated.
Both of these are temporary and can always be regenerated by running the script again, so it is safe to delete them and they are excluded from version control in `.gitignore`.

## Create a pipeline

After uploading all artifacts (IDS, task script and protocol), you can go to the Tetra Data Platform and set up a new pipeline by selecting the protocol by its name.
The full documentation for creating pipelines is here: https://developers.tetrascience.com/docs/managing-pipelines

## Artifact identity (namespace, type slug and version)

The namespace of this example is `private-{YOUR_ORG_SLUG}`, the type slug is `demo-ssp`, and the version is `v0.1.0`.
This is often put together in one string as `private-{YOUR_ORG_SLUG}/demo-ssp:v0.1.0`.

The combination of the kind of artifact (IDS, task script or protocol), namespace, slug and version uniquely identifies an artifact.

In this example, the slug `demo-ssp` is the same for the IDS, task script and protocol, but it is also possible for each to have a different slug.

The IDS namespace, type slug and version are defined in these files:

```
.
├── ids
│  ├── manifest.json
│  └── demo_ssp_ids
│     └── schema.py - `Model.NAMESPACE`, `Model.TYPE` and `Model.VERSION`
└── task_script
   └── config.json - The task script specifies its IDS output type in "allowedIds"
```

Additionally, by running `poetry run pytest --snapshot-update` after changing the above files, the namespace, slug and version will be updated in `ids/schema.json`, `ids/expected.json`, and the IDS JSON files in `example-output`.

The task script namespace, type slug and version are defined in these files:

```
.
├── task_script
│  └── manifest.json
└── protocol
   └── protocol.yml - The protocol specifies which task script(s) it uses in `steps`
```

The protocol namespace, type slug and version are defined in these files:

```
.
└── protocol
   └── manifest.json
```
